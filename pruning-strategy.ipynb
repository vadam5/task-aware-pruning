{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75ec25fe-bed3-43a9-94e8-22413302a7a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "from node_attribution.gradient_node_attribution import get_attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd5f02b6-a727-47ed-baf0-14ae880caa13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "human_filtered_pairs = pkl.load(open(\"44_human_filtered_conv_pairs.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9cc4ca1-1604-4734-925b-39eed900da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_data = human_filtered_pairs[:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8efbe0a3-048c-4ca6-a77e-dfe9315161ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/qm/qmg6cwns11x93fg6_77cntd40000gn/T/ipykernel_985/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3399721117.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/qm/qmg6cwns11x93fg6_77cntd40000gn/T/ipykernel_985/3399721117.py'</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/virginiaadams/Projects/task-aware-pruning/node_attribution/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">gradient_node_attribution.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">7</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">8</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_attributions</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 75 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> contributions                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 76 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 77 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_attributions</span>(model_size, data):                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 78 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>attributor = BloomNodeAttributor(model_size)                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 79 │   </span>contributions = attributor.calc_node_contributions(data)                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 80 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 81 │   </span>avg_contribution = OrderedDict()                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/virginiaadams/Projects/task-aware-pruning/node_attribution/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">gradient_node_attribution.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">6</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 13 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 14 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">class</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; text-decoration: underline\">BloomNodeAttributor</span>:                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 15 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, model_size):                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 16 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.load_bloom_model(model_size)                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 17 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 18 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load_bloom_model</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, model_size):                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 19 │   │   </span>logging.info(<span style=\"color: #808000; text-decoration-color: #808000\">f\"Starting to load bigscience/bloom-{</span>model_size<span style=\"color: #808000; text-decoration-color: #808000\">} ...\"</span>)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/virginiaadams/Projects/task-aware-pruning/node_attribution/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">gradient_node_attribution.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load_bloom_model</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 19 │   │   </span>logging.info(<span style=\"color: #808000; text-decoration-color: #808000\">f\"Starting to load bigscience/bloom-{</span>model_size<span style=\"color: #808000; text-decoration-color: #808000\">} ...\"</span>)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 20 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 21 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.tokenizer = AutoTokenizer.from_pretrained(<span style=\"color: #808000; text-decoration-color: #808000\">f\"bigscience/bloom-{</span>model_size<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>)   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 22 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model = BloomForCausalLMForNodeAttribution.from_pretrained(<span style=\"color: #808000; text-decoration-color: #808000\">f\"bigscience/blo</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 23 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 24 │   │   </span>logging.info(<span style=\"color: #808000; text-decoration-color: #808000\">f\"bigscience/bloom-{</span>model_size<span style=\"color: #808000; text-decoration-color: #808000\">} loaded, counting params and calcula</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 25 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2362</span> in                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2359 │   │   │   </span>init_contexts.append(init_empty_weights())                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2360 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2361 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> ContextManagers(init_contexts):                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2362 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>model = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>(config, *model_args, **model_kwargs)                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2363 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2364 │   │   # Check first if we are `from_pt`</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2365 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> use_keep_in_fp32_modules:                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/virginiaadams/Projects/task-aware-pruning/node_attribution/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">bloom_for_gradient_node_attrib</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ution.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">458</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">455 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">class</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; text-decoration: underline\">BloomForCausalLMForNodeAttribution</span>(BloomForCausalLM, GenerationMixinForNodeAttribu   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">456 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, config: BloomConfig):                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">457 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>(config)                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>458 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.transformer = BloomModelForNodeAttribution(config)                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">459 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>)        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">460 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">461 │   │   # Initialize weights and apply final processing</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/virginiaadams/Projects/task-aware-pruning/node_attribution/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">bloom_for_gradient_node_attrib</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ution.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">296</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">293 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.word_embeddings_layernorm = LayerNorm(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.embed_dim, eps=config.layer_norm   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">294 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">295 │   │   # Transformer blocks</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>296 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.h = nn.ModuleList([BloomBlockForNodeAttribution(config) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> _ <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(conf   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">297 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">298 │   │   # Final Layer Norm</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">299 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ln_f = LayerNorm(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.embed_dim, eps=config.layer_norm_epsilon)               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/virginiaadams/Projects/task-aware-pruning/node_attribution/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">bloom_for_gradient_node_attrib</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ution.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">296</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;listcomp&gt;</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">293 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.word_embeddings_layernorm = LayerNorm(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.embed_dim, eps=config.layer_norm   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">294 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">295 │   │   # Transformer blocks</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>296 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.h = nn.ModuleList([BloomBlockForNodeAttribution(config) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> _ <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(conf   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">297 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">298 │   │   # Final Layer Norm</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">299 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ln_f = LayerNorm(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.embed_dim, eps=config.layer_norm_epsilon)               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/virginiaadams/Projects/task-aware-pruning/node_attribution/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">bloom_for_gradient_node_attrib</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ution.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">213</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">210 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">211 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.input_layernorm = LayerNorm(hidden_size, eps=config.layer_norm_epsilon)       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">212 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.num_heads = config.n_head                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>213 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.self_attention = BloomAttentionForNodeAttribution(config)                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">214 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.post_attention_layernorm = LayerNorm(hidden_size, eps=config.layer_norm_eps   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">215 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">216 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.mlp = BloomMLPForNodeAttribution(config)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/virginiaadams/Projects/task-aware-pruning/node_attribution/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">bloom_for_gradient_node_attrib</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ution.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">56</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 53 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 54 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">class</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; text-decoration: underline\">BloomAttentionForNodeAttribution</span>(BloomAttention):                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 55 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, config):                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 56 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>(config).<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>()                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 57 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 58 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.pretraining_tp = config.pretraining_tp                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 59 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.slow_but_exact = config.slow_but_exact                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">super</span><span style=\"font-weight: bold\">()</span> argument <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> must be type, not BloomConfig\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/var/folders/qm/qmg6cwns11x93fg6_77cntd40000gn/T/ipykernel_985/\u001b[0m\u001b[1;33m3399721117.py\u001b[0m:\u001b[94m3\u001b[0m in \u001b[92m<module>\u001b[0m       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'/var/folders/qm/qmg6cwns11x93fg6_77cntd40000gn/T/ipykernel_985/3399721117.py'\u001b[0m                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/virginiaadams/Projects/task-aware-pruning/node_attribution/\u001b[0m\u001b[1;33mgradient_node_attribution.py\u001b[0m:\u001b[94m7\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m8\u001b[0m in \u001b[92mget_attributions\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 75 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m contributions                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 76 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 77 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mget_attributions\u001b[0m(model_size, data):                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 78 \u001b[2m│   \u001b[0mattributor = BloomNodeAttributor(model_size)                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 79 \u001b[0m\u001b[2m│   \u001b[0mcontributions = attributor.calc_node_contributions(data)                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 80 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 81 \u001b[0m\u001b[2m│   \u001b[0mavg_contribution = OrderedDict()                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/virginiaadams/Projects/task-aware-pruning/node_attribution/\u001b[0m\u001b[1;33mgradient_node_attribution.py\u001b[0m:\u001b[94m1\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m6\u001b[0m in \u001b[92m__init__\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 13 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 14 \u001b[0m\u001b[94mclass\u001b[0m \u001b[4;92mBloomNodeAttributor\u001b[0m:                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 15 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__init__\u001b[0m(\u001b[96mself\u001b[0m, model_size):                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 16 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.load_bloom_model(model_size)                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 17 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 18 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mload_bloom_model\u001b[0m(\u001b[96mself\u001b[0m, model_size):                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 19 \u001b[0m\u001b[2m│   │   \u001b[0mlogging.info(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mStarting to load bigscience/bloom-\u001b[0m\u001b[33m{\u001b[0mmodel_size\u001b[33m}\u001b[0m\u001b[33m ...\u001b[0m\u001b[33m\"\u001b[0m)                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/virginiaadams/Projects/task-aware-pruning/node_attribution/\u001b[0m\u001b[1;33mgradient_node_attribution.py\u001b[0m:\u001b[94m2\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m2\u001b[0m in \u001b[92mload_bloom_model\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 19 \u001b[0m\u001b[2m│   │   \u001b[0mlogging.info(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mStarting to load bigscience/bloom-\u001b[0m\u001b[33m{\u001b[0mmodel_size\u001b[33m}\u001b[0m\u001b[33m ...\u001b[0m\u001b[33m\"\u001b[0m)                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 20 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 21 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.tokenizer = AutoTokenizer.from_pretrained(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mbigscience/bloom-\u001b[0m\u001b[33m{\u001b[0mmodel_size\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 22 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.model = BloomForCausalLMForNodeAttribution.from_pretrained(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mbigscience/blo\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 23 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 24 \u001b[0m\u001b[2m│   │   \u001b[0mlogging.info(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mbigscience/bloom-\u001b[0m\u001b[33m{\u001b[0mmodel_size\u001b[33m}\u001b[0m\u001b[33m loaded, counting params and calcula\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 25 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mmodeling_utils.py\u001b[0m:\u001b[94m2362\u001b[0m in                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mfrom_pretrained\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2359 \u001b[0m\u001b[2m│   │   │   \u001b[0minit_contexts.append(init_empty_weights())                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2360 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2361 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m ContextManagers(init_contexts):                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2362 \u001b[2m│   │   │   \u001b[0mmodel = \u001b[96mcls\u001b[0m(config, *model_args, **model_kwargs)                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2363 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2364 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Check first if we are `from_pt`\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2365 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m use_keep_in_fp32_modules:                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/virginiaadams/Projects/task-aware-pruning/node_attribution/\u001b[0m\u001b[1;33mbloom_for_gradient_node_attrib\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mution.py\u001b[0m:\u001b[94m458\u001b[0m in \u001b[92m__init__\u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m455 \u001b[0m\u001b[94mclass\u001b[0m \u001b[4;92mBloomForCausalLMForNodeAttribution\u001b[0m(BloomForCausalLM, GenerationMixinForNodeAttribu   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m456 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__init__\u001b[0m(\u001b[96mself\u001b[0m, config: BloomConfig):                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m457 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96msuper\u001b[0m().\u001b[92m__init__\u001b[0m(config)                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m458 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.transformer = BloomModelForNodeAttribution(config)                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m459 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=\u001b[94mFalse\u001b[0m)        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m460 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m461 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Initialize weights and apply final processing\u001b[0m                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/virginiaadams/Projects/task-aware-pruning/node_attribution/\u001b[0m\u001b[1;33mbloom_for_gradient_node_attrib\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mution.py\u001b[0m:\u001b[94m296\u001b[0m in \u001b[92m__init__\u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m293 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.word_embeddings_layernorm = LayerNorm(\u001b[96mself\u001b[0m.embed_dim, eps=config.layer_norm   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m294 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m295 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Transformer blocks\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m296 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.h = nn.ModuleList([BloomBlockForNodeAttribution(config) \u001b[94mfor\u001b[0m _ \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(conf   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m297 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m298 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Final Layer Norm\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m299 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.ln_f = LayerNorm(\u001b[96mself\u001b[0m.embed_dim, eps=config.layer_norm_epsilon)               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/virginiaadams/Projects/task-aware-pruning/node_attribution/\u001b[0m\u001b[1;33mbloom_for_gradient_node_attrib\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mution.py\u001b[0m:\u001b[94m296\u001b[0m in \u001b[92m<listcomp>\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m293 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.word_embeddings_layernorm = LayerNorm(\u001b[96mself\u001b[0m.embed_dim, eps=config.layer_norm   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m294 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m295 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Transformer blocks\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m296 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.h = nn.ModuleList([BloomBlockForNodeAttribution(config) \u001b[94mfor\u001b[0m _ \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(conf   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m297 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m298 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Final Layer Norm\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m299 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.ln_f = LayerNorm(\u001b[96mself\u001b[0m.embed_dim, eps=config.layer_norm_epsilon)               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/virginiaadams/Projects/task-aware-pruning/node_attribution/\u001b[0m\u001b[1;33mbloom_for_gradient_node_attrib\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mution.py\u001b[0m:\u001b[94m213\u001b[0m in \u001b[92m__init__\u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m210 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m211 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.input_layernorm = LayerNorm(hidden_size, eps=config.layer_norm_epsilon)       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m212 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.num_heads = config.n_head                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m213 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.self_attention = BloomAttentionForNodeAttribution(config)                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m214 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.post_attention_layernorm = LayerNorm(hidden_size, eps=config.layer_norm_eps   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m215 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m216 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.mlp = BloomMLPForNodeAttribution(config)                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/virginiaadams/Projects/task-aware-pruning/node_attribution/\u001b[0m\u001b[1;33mbloom_for_gradient_node_attrib\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mution.py\u001b[0m:\u001b[94m56\u001b[0m in \u001b[92m__init__\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 53 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 54 \u001b[0m\u001b[94mclass\u001b[0m \u001b[4;92mBloomAttentionForNodeAttribution\u001b[0m(BloomAttention):                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 55 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__init__\u001b[0m(\u001b[96mself\u001b[0m, config):                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 56 \u001b[2m│   │   \u001b[0m\u001b[96msuper\u001b[0m(config).\u001b[92m__init__\u001b[0m()                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 57 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 58 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.pretraining_tp = config.pretraining_tp                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 59 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.slow_but_exact = config.slow_but_exact                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0m\u001b[1;35msuper\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m argument \u001b[1;36m1\u001b[0m must be type, not BloomConfig\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get attributions\n",
    "model_size = \"1b7\"\n",
    "avg_contributions, max_contributions, model, model_params = get_attributions(model_size, [calibration_data[0][5:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9b7a08a-65d7-4158-9e60-fd6839f59c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take absolute value of average contributions\n",
    "for layer_name, contribution_tensor in avg_contributions.items():\n",
    "    avg_contributions[layer_name] = torch.abs(avg_contributions[layer_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7840688f-5c3f-4670-b280-0e7a26cef4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pkl.dump(avg_contributions, open(\"avg_contri_3B_22pair_calibration.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d57fcb4a-9f44-48d3-9267-5620a8dcfb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pkl.dump(max_contributions, open(\"max_contri_3B_22pair_calibration.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01fa3686-3fb2-4441-8d0b-2df9ff857ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_contributions = pkl.load(open(\"avg_contri_560m_22pair_calibration.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "289d2a47-0d93-43ad-897b-3ae05dfcce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_percent = 0.05\n",
    "num_params_to_prune = 3002557440 * prune_percent\n",
    "\n",
    "head_dim = 80\n",
    "num_heads = 32\n",
    "hidden_size = 2560"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4e880a64-b350-4423-9298-5ef32f86976c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "params_to_index = {}\n",
    "for param_name in model_params.keys():\n",
    "    if \"bias\" not in param_name:\n",
    "        params_to_index[param_name] = index\n",
    "        index += 1\n",
    "    \n",
    "index_to_params = {params_to_index[param_name]: param_name for param_name in params_to_index.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "830cf301-0660-43f4-839c-02016f3bb33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_shape_map = {}\n",
    "layer_names, contribution_tensors = zip(*avg_contributions.items())\n",
    "num_layers = len(layer_names)\n",
    "\n",
    "for i in range(num_layers):\n",
    "    layer_name = layer_names[i]\n",
    "    layer_size = contribution_tensors[i].shape[0]\n",
    "    \n",
    "    if i != 0:\n",
    "        next_layer_size = contribution_tensors[i - 1].shape[0]\n",
    "    else:\n",
    "        next_layer_size = 250880\n",
    "        \n",
    "    \n",
    "    if i != (num_layers - 1):\n",
    "        prev_layer_size = contribution_tensors[i + 1].shape[0]\n",
    "    else:\n",
    "        prev_layer_size = 1024\n",
    "        \n",
    "    layer_shape_map[layer_name] = {\n",
    "        \"prev_layer_size\": prev_layer_size,\n",
    "        \"next_layer_size\": next_layer_size,\n",
    "        \"current_layer_size\": layer_size\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "52304b74-b166-4c13-a95f-2eafc0c3a705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_nodes = []\n",
    "\n",
    "for layer_name, contribution_tensor in avg_contributions.items():\n",
    "    for node_id, node in enumerate(contribution_tensor.tolist()):\n",
    "        node_name = f\"{layer_name}.{node_id}\"\n",
    "        all_nodes.append((node_name, node))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "fee0d3a6-0b98-4e18-9940-34b0f3ed7db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort all the nodes\n",
    "all_nodes.sort(key = lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7061e785-c991-4e60-b4c3-80bfb778cf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_layers = []\n",
    "\n",
    "# Figure out which layers have the most to prune\n",
    "for layer_name, contribution_tensor in avg_contributions.items():\n",
    "    \n",
    "    # Don't prune self_attention.dense.weight directly, use value matrix to decide what to prune\n",
    "    if \"self_attention.dense.weight\" in layer_name:\n",
    "        continue\n",
    "        \n",
    "    if \"mlp.dense_h_to_4h.weight\" in layer_name:\n",
    "        continue\n",
    "        \n",
    "    if \"self_attention.query_key_value.weight\" in layer_name:\n",
    "        continue\n",
    "        \n",
    "    if \"transformer.ln_f.weight\" in layer_name:\n",
    "        continue\n",
    "        \n",
    "    if \"lm_head.weight\" in layer_name:\n",
    "        continue\n",
    "    \n",
    "    # Get average contribution over the whole layer\n",
    "    mean_contribution = torch.mean(contribution_tensor, 0).item()\n",
    "    all_layers.append((layer_name, mean_contribution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6568baf2-3382-4e41-a309-e20b827d8830",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_layers.sort(key = lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b6f75b8e-7803-464c-b368-21c453ba0725",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_masks = {}\n",
    "num_params_pruned = 0\n",
    "node_num = 0\n",
    "min_nodes = 24\n",
    "value_dim = 2\n",
    "\n",
    "while num_params_pruned < num_params_to_prune:\n",
    "    lowest_contr_layer_name = all_layers[0][0]               \n",
    "    shapes = layer_shape_map[lowest_contr_layer_name] \n",
    "    stop_pruning_layer = False\n",
    " \n",
    "    # Prune one node at time\n",
    "    if lowest_contr_layer_name not in layer_masks:\n",
    "        layer_contributions = avg_contributions[lowest_contr_layer_name]\n",
    "        mask = torch.zeros_like(layer_contributions)\n",
    "        sorted_contributions = torch.argsort(layer_contributions)\n",
    "        num_pruned = 0\n",
    "\n",
    "    else:\n",
    "        mask = layer_masks[lowest_contr_layer_name][0]\n",
    "        sorted_contributions = layer_masks[lowest_contr_layer_name][1]\n",
    "        num_pruned = layer_masks[lowest_contr_layer_name][2]\n",
    "\n",
    "    index_to_mask = sorted_contributions[num_pruned]\n",
    "    mask[index_to_mask] = 1\n",
    "\n",
    "    nodes_left = torch.numel(mask) - int(torch.sum(mask).item())\n",
    "\n",
    "    # Keep from deleting all nodes in a layer\n",
    "    if nodes_left > min_nodes:\n",
    "        layer_masks[lowest_contr_layer_name] = (mask, sorted_contributions, num_pruned + 1)\n",
    "        # num_params_pruned += shapes[\"prev_layer_size\"]\n",
    "        # num_params_pruned += shapes[\"next_layer_size\"]\n",
    "        num_params_pruned += hidden_size * 2\n",
    "        node_num += 1\n",
    "    else:\n",
    "        stop_pruning_layer = True\n",
    "\n",
    "    # Apply mask and update the layer mean in \"all_layers\"\n",
    "    if stop_pruning_layer:\n",
    "        new_layer_contr_score = float('inf')\n",
    "    else:\n",
    "        mean_array = np.ma.array(data=avg_contributions[lowest_contr_layer_name], mask=mask)\n",
    "        new_layer_contr_score = mean_array.mean()\n",
    "\n",
    "    # print(all_layers[0])\n",
    "    all_layers[0] = (lowest_contr_layer_name, new_layer_contr_score)\n",
    "    # print(all_layers[0])\n",
    "    # print(f\"Num params removed: {num_params_pruned}\")\n",
    "    # print(f\"Num Nodes removed: {node_num}\")\n",
    "    # print(\"=====\")\n",
    "    \n",
    "    # re-sort layers now that this one has been pruned and pick the lowest contributing layer again\n",
    "    all_layers.sort(key = lambda x:x[1])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "fc0d48da-8f45-4f78-a502-ed4e413b6799",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Line up weights to prune and weights in the state dict\n",
    "mask_index = 0\n",
    "sorted_weight_index = 1\n",
    "pruned_model_params = model_params.copy()\n",
    "\n",
    "for layer_name in layer_masks.keys():\n",
    "    if layer_name == \"transformer.h.0.self_attention.query_key_value.weight\":\n",
    "        continue\n",
    "    elif \"self_attention.value_layer.weight\" in layer_name:   \n",
    "        # Prune as input\n",
    "        # Look at value matrix to decide what should be droped in \"self_attention.dense.weight\"\n",
    "        value_reshape_mask = layer_masks[layer_name][mask_index].transpose(0, 1)[-1].reshape(num_heads * head_dim)\n",
    "        num_nodes_to_drop = int(sum(value_reshape_mask).item())\n",
    "        value_indices = layer_masks[layer_name][sorted_weight_index].transpose(0, 1)[-1].reshape(num_heads * head_dim)\n",
    "        value_keep_index = torch.sort(value_indices[num_nodes_to_drop:]).values\n",
    "        \n",
    "        dense_layer_name = layer_name.replace(\"value_layer\", \"dense\")\n",
    "        pruned_input_weights = torch.index_select(pruned_model_params[dense_layer_name], -1, value_keep_index)\n",
    "        pruned_model_params[dense_layer_name] = pruned_input_weights\n",
    "        \n",
    "        # Re-arrange mask to flatten shape\n",
    "        reshaped_mask = layer_masks[layer_name][mask_index].view(num_heads * 3 * head_dim)\n",
    "        rehsaped_indices = layer_masks[layer_name][sorted_weight_index].view(num_heads * 3 * head_dim)\n",
    "        num_nodes_to_drop = int(sum(reshaped_mask).item())\n",
    "        keep_index = torch.sort(rehsaped_indices[num_nodes_to_drop:]).values\n",
    "        \n",
    "        # Prune as output\n",
    "        prev_layer_name = layer_name.replace(\"value_layer\", \"query_key_value\")\n",
    "        pruned_output_weights = torch.index_select(pruned_model_params[prev_layer_name], 0, keep_index)\n",
    "        pruned_model_params[prev_layer_name] = pruned_output_weights\n",
    "        \n",
    "        # Also do bias term\n",
    "        bias_layer_name = prev_layer_name.replace(\"weight\", \"bias\")\n",
    "        pruned_bias_weights = torch.index_select(pruned_model_params[bias_layer_name], 0, keep_index)\n",
    "        pruned_model_params[bias_layer_name] = pruned_bias_weights\n",
    "        \n",
    "    else:\n",
    "        # Prune when nodes are the input\n",
    "        num_nodes_to_drop = int(sum(layer_masks[layer_name][mask_index]).item())\n",
    "        keep_index = torch.sort(layer_masks[layer_name][sorted_weight_index][num_nodes_to_drop:]).values\n",
    "        pruned_input_weights = torch.index_select(pruned_model_params[layer_name], -1, keep_index)\n",
    "        pruned_model_params[layer_name] = pruned_input_weights\n",
    "        \n",
    "        # Go to previous layer and prune when nodes are the output\n",
    "        prev_layer_index = params_to_index[layer_name] - 1\n",
    "        prev_layer_name = index_to_params[prev_layer_index]\n",
    "        \n",
    "        if \"layernorm\" in prev_layer_name:\n",
    "            pruned_layer_norm_weights = torch.index_select(pruned_model_params[prev_layer_name], 0, keep_index)\n",
    "            pruned_model_params[prev_layer_name] = pruned_layer_norm_weights \n",
    "            \n",
    "            # Also do bias term\n",
    "            bias_layer_name = prev_layer_name.replace(\"weight\", \"bias\")\n",
    "            pruned_bias_weights = torch.index_select(pruned_model_params[bias_layer_name], 0, keep_index)\n",
    "            pruned_model_params[bias_layer_name] = pruned_bias_weights\n",
    "            \n",
    "            prev_layer_index = prev_layer_index - 1\n",
    "            prev_layer_name = index_to_params[prev_layer_index]\n",
    "            \n",
    "        pruned_output_weights = torch.index_select(pruned_model_params[prev_layer_name], 0, keep_index)\n",
    "        pruned_model_params[prev_layer_name] = pruned_output_weights\n",
    "        \n",
    "        # Also do bias term\n",
    "        bias_layer_name = prev_layer_name.replace(\"weight\", \"bias\")\n",
    "        pruned_bias_weights = torch.index_select(pruned_model_params[bias_layer_name], 0, keep_index)\n",
    "        pruned_model_params[bias_layer_name] = pruned_bias_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "fdb4a783-6cd1-44f9-b4e9-a3dd2f5b0156",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pruned_model_params, \"pruned_05percent_3B_bloom.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9b70a7e7-b902-4ecd-8c82-bb0764f3b9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict_shapes = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "7ae74350-2038-435f-b708-e38f0cdee675",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for param_name in pruned_model_params.keys():\n",
    "    state_dict_shapes[param_name] = pruned_model_params[param_name].shape\n",
    "    #print(param_name, pruned_model_params[param_name].shape)\n",
    "    \n",
    "pkl.dump(state_dict_shapes, open(\"pruned_05percent_3B_bloom_state_dict_shapes.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "28af6ba2-5c54-4693-a1ba-56cc2d8da64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09544921875"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_num / len(all_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "81c1d532-4970-4891-88a0-b1110c867364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29322"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beff6b26-2dd6-4776-8cd7-d7551442b756",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tap",
   "language": "python",
   "name": "tap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
